{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Multi-Layer Perceptron in Keras\n",
    "\n",
    "In this demo we'll try to build a Multi-Layer Perceptron using the library Keras. The Keras functionality is also available in Tensorflow if you import ```tf.keras``` instead of ```keras``` directly.\n",
    "\n",
    "It is very simple to create an MLP in Keras and it can be done in a few steps.\n",
    "\n",
    "Let's just import some stuff first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,), (102, 13), (102,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the Boston Housing Dataset as an example. It's a regression problem. This means the number of neurons in the last layer will always be equal to 1.\n",
    "\n",
    "There are two ways of creating models in Keras, using the ```Sequential``` model and using the ```Model``` class. We'll do it using the first way this time.\n",
    "\n",
    "**Steps**\n",
    "1. Initialise model as ```Sequential()```.\n",
    "2. Keep adding layers to it using the ```add()``` method.\n",
    "3. Compile model using the ```compile()``` method.\n",
    "4. Fit the training set using the ```fit()``` method.\n",
    "5. Make predictions and evaluate using either the ```predict()``` method or ```evaluate()``` method.\\\n",
    "\n",
    "**Some things to remember**\n",
    "1. The dimension of first layer will be the number of columns in the dataset and dimension of last layer will be according to the problem (see table below).\n",
    "2. Activations in the hidden layers should most probably be ```ReLU``` or ```LeakyReLU```.They usually work best.\n",
    "3. Deeper networks always learn more complex things, but if the dataset is small, you'll benefit from a shallow network.\n",
    "4. Some things about the architecture vary depending on the problem:\n",
    "\n",
    "| **Problem type** | **Dimension of output layer** | **Loss** | **Activation of last layer** | **Some metrics** |\n",
    "| --- |:---:|:---:|:---:|---:|\n",
    "| Regression | 1 | ```mean_squared_error``` | None | mae, mse |\n",
    "| Binary classification | 1 | ```binary_crossentropy``` | Sigmoid | accuracy |\n",
    "| Multi-class classification | No. of classes | ```categorical_crossentropy``` | Softmax | accuracy |\n",
    "\n",
    "\n",
    "Finally, Keras offers a wide variety of layers, but the ones that we are interested in this lab are ```Dense``` and ```Dropout```. ```Dense``` is your typical fully connected layer in an MLP, while ```Dropout``` is a special kind of layer designed for regularization in Keras models (will be explained in lab today or in the next lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile \n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/15\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 7304.1807 - mean_absolute_error: 65.8723 - val_loss: 2972.7948 - val_mean_absolute_error: 44.3155\n",
      "Epoch 2/15\n",
      "323/323 [==============================] - 0s 81us/step - loss: 4522.4053 - mean_absolute_error: 50.8230 - val_loss: 1812.1483 - val_mean_absolute_error: 33.3471\n",
      "Epoch 3/15\n",
      "323/323 [==============================] - 0s 114us/step - loss: 3209.8157 - mean_absolute_error: 42.9727 - val_loss: 1126.0498 - val_mean_absolute_error: 25.6689\n",
      "Epoch 4/15\n",
      "323/323 [==============================] - 0s 135us/step - loss: 2136.2768 - mean_absolute_error: 33.7298 - val_loss: 744.2957 - val_mean_absolute_error: 20.6018\n",
      "Epoch 5/15\n",
      "323/323 [==============================] - 0s 131us/step - loss: 1483.1817 - mean_absolute_error: 27.7305 - val_loss: 576.3978 - val_mean_absolute_error: 18.5690\n",
      "Epoch 6/15\n",
      "323/323 [==============================] - 0s 184us/step - loss: 1070.4311 - mean_absolute_error: 24.5391 - val_loss: 463.5397 - val_mean_absolute_error: 16.5361\n",
      "Epoch 7/15\n",
      "323/323 [==============================] - 0s 156us/step - loss: 733.8181 - mean_absolute_error: 21.2429 - val_loss: 416.2765 - val_mean_absolute_error: 15.5153\n",
      "Epoch 8/15\n",
      "323/323 [==============================] - 0s 190us/step - loss: 645.7631 - mean_absolute_error: 19.7820 - val_loss: 398.4192 - val_mean_absolute_error: 14.9975\n",
      "Epoch 9/15\n",
      "323/323 [==============================] - 0s 142us/step - loss: 605.7170 - mean_absolute_error: 19.5670 - val_loss: 387.6291 - val_mean_absolute_error: 14.7971\n",
      "Epoch 10/15\n",
      "323/323 [==============================] - 0s 123us/step - loss: 661.2510 - mean_absolute_error: 20.0271 - val_loss: 379.3387 - val_mean_absolute_error: 14.7443\n",
      "Epoch 11/15\n",
      "323/323 [==============================] - 0s 109us/step - loss: 501.4578 - mean_absolute_error: 17.9010 - val_loss: 375.8073 - val_mean_absolute_error: 14.9485\n",
      "Epoch 12/15\n",
      "323/323 [==============================] - 0s 180us/step - loss: 449.6500 - mean_absolute_error: 16.8611 - val_loss: 369.4800 - val_mean_absolute_error: 14.9564\n",
      "Epoch 13/15\n",
      "323/323 [==============================] - 0s 157us/step - loss: 447.3887 - mean_absolute_error: 16.8940 - val_loss: 363.7331 - val_mean_absolute_error: 14.9059\n",
      "Epoch 14/15\n",
      "323/323 [==============================] - 0s 138us/step - loss: 342.5090 - mean_absolute_error: 15.3876 - val_loss: 351.4620 - val_mean_absolute_error: 14.6378\n",
      "Epoch 15/15\n",
      "323/323 [==============================] - 0s 163us/step - loss: 374.3107 - mean_absolute_error: 15.8642 - val_loss: 343.0933 - val_mean_absolute_error: 14.4102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe056783048>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the training set on the model\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What did I make?**\n",
    "\n",
    "You can print the summary of the model using the ```summary()``` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 258\n",
      "Trainable params: 258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now our model is small and shallow and so you probably don't need the ```summary()``` method. But for large networks, typically with Convolutional Networks, you should pay attention to the number of parameters, as this will give you an estimate about if the model will be trainable in your CPU or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test = 14.288117753801979\n"
     ]
    }
   ],
   "source": [
    "print (\"MAE on test =\", mean_absolute_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other important related stuff which you can use in Keras and references (**you should absolutely read these**):\n",
    "1. [Early Stopping](https://chrisalbon.com/deep_learning/keras/neural_network_early_stopping/)\n",
    "2. [Model Checkpoint](https://chrisalbon.com/deep_learning/keras/neural_network_early_stopping/)\n",
    "3. [Dropout](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/)\n",
    "4. [Batch Normalization](https://www.dlology.com/blog/one-simple-trick-to-train-keras-model-faster-with-batch-normalization/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
