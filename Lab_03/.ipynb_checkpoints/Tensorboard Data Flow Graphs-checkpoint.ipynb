{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensorboard\n",
    "\n",
    "Tensorboard is a creative tool provided by the creators of TensorFlow for visualizing the data flow graphs, values of scalars (training error, validation accuracy, etc.), images, histograms and much more while training models. We will explore Tensorboard over the course, and this demo is aimed at introducing this tool.\n",
    "\n",
    "In this demo, we'll learn how to visualize the computation graph of a model and how to organize it in a neat and understandable manner. This can be extremely useful when debugging your model.\n",
    "\n",
    "Follow this link to learn more about visualizing Data flow graphs using Tensorboard: https://databricks.com/tensorflow/visualisation\n",
    "\n",
    "The next few cells just load the data and initialize the hyperparameters. Nothing much to see here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Breast Cancer dataset.\n",
      "\n",
      "Train set:\n",
      "# of samples = 455\n",
      "# of features = 30\n",
      "\n",
      "Test set:\n",
      "# of samples = 114\n",
      "# of features = 30\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(test_size=0.2):\n",
    "    print (\"Using the Breast Cancer dataset.\")\n",
    "    print (\"\")\n",
    "    \n",
    "    # Download the breast cancer dataset\n",
    "    dataset = load_breast_cancer()\n",
    "    x, y = dataset['data'], dataset['target']\n",
    "    x_t, x_t_, y_t, y_t_ = train_test_split(x, y, test_size=test_size, random_state=10)\n",
    "\n",
    "    # Reshape y_train and y_test\n",
    "    y_t = np.reshape(y_t, (y_t.shape[0], 1))\n",
    "    y_t_ = np.reshape(y_t_, (y_t_.shape[0], 1))\n",
    "\n",
    "    # Print details of dataset\n",
    "    print (\"Train set:\")\n",
    "    print (\"# of samples =\", x_t.shape[0])\n",
    "    print (\"# of features =\", x_t.shape[1])\n",
    "    print (\"\")\n",
    "    print (\"Test set:\")\n",
    "    print (\"# of samples =\", x_t_.shape[0])\n",
    "    print (\"# of features =\", x_t_.shape[1])\n",
    "    \n",
    "    return x_t, y_t, x_t_, y_t_\n",
    "\n",
    "x_t, y_t, x_t_, y_t_ = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "\n",
    "ALPHA = 0.01 # Learning rate\n",
    "NUM_EPOCHS = 10 # Number of epochs\n",
    "NUM_FEATURES = x_t.shape[1] # Number of features for that perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic visualization**\n",
    "\n",
    "To start using Tensorboard:\n",
    "1. Open the terminal in the same directory you are in and create an empty directory named 'logs' (it can also be anything else, according to your choice; make sure you change the ```logdir``` variable in the next cell accordingly).\n",
    "2. Run the next two cells.\n",
    "3. Type in the terminal: \n",
    "```tensorboard --logdir logs```.\n",
    "4. Open the link provided.\n",
    "\n",
    "Voila!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the model\n",
    "\n",
    "# For Tensorboard\n",
    "logdir = './logs'\n",
    "\n",
    "# To erase any default graphs created before\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholders for the features and labels\n",
    "x_train = tf.placeholder(tf.float32, shape=x_t.shape, name='x_train')\n",
    "y_train = tf.placeholder(tf.float32, shape=(y_t.shape[0], 1), name='y_train')\n",
    "\n",
    "# Weight and bias variables\n",
    "W = tf.Variable(tf.zeros([NUM_FEATURES, 1]), tf.float32, name='weights')\n",
    "b = tf.Variable(tf.zeros([1, 1]), tf.float32, name='bias')\n",
    "\n",
    "# Calculate the predicted value\n",
    "y_hat = tf.sigmoid(tf.add(tf.matmul(x_train, W), b))\n",
    "\n",
    "# Calculate errors\n",
    "errors = y_train - y_hat\n",
    "\n",
    "# Calculate the gradients for weights and bias\n",
    "del_W = tf.matmul(tf.transpose(x_train), errors)\n",
    "del_b = tf.reduce_sum(errors, 0)\n",
    "\n",
    "# Update weights\n",
    "W_ = W + ALPHA*del_W\n",
    "b_ = b + ALPHA*del_b\n",
    "\n",
    "# Create an op and assign operations to it\n",
    "step = tf.group(W.assign(W_), b.assign(b_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #01: train_loss = 0.11978\n",
      "Epoch #02: train_loss = 0.61978\n",
      "Epoch #03: train_loss = -0.38022\n",
      "Epoch #04: train_loss = 0.61978\n",
      "Epoch #05: train_loss = -0.38022\n",
      "Epoch #06: train_loss = 0.61978\n",
      "Epoch #07: train_loss = 0.61978\n",
      "Epoch #08: train_loss = -0.38022\n",
      "Epoch #09: train_loss = 0.61978\n",
      "Epoch #10: train_loss = -0.38022\n"
     ]
    }
   ],
   "source": [
    "## Session\n",
    "\n",
    "# Create a TensorFlow session\n",
    "with tf.Session() as sess:\n",
    "    # Initialize global variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "    \n",
    "    # Train the model\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        print (\"Epoch #{0:02d}\".format(i+1) + \":\", end=' ')\n",
    "        _, outs = sess.run([step, errors], feed_dict={x_train:x_t, y_train:y_t})\n",
    "        outs = [item for sublist in outs for item in sublist]\n",
    "        training_error = np.mean(outs)\n",
    "        print (\"train_loss = {0:0.5f}\".format(training_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that to make this work we added the line\n",
    "\n",
    "```writer = tf.summary.FileWriter(logdir, sess.graph)```\n",
    "\n",
    "in the second cell. The value of ```logdir``` is the name of the directory we want to put the logs into. The ```FileWriter``` class creates an event file which is stored in the ```logs``` directory. When you start Tensorboard and mention that the directory to look into is ```logs``` (by writing this part of the command: ```--logdir logs```), Tensorboard automatically checks this directory for event files and opens them.\n",
    "\n",
    "It is important to remember not to put more than one event file in the log directory as it might mess up the visuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using namespaces**\n",
    "\n",
    "Is this graph neat and understandable? Probably not. This problem can be solved using namespaces. We can group variables into namespaces by initializing them under namespace blocks as follows:\n",
    "\n",
    "**Note**: Make sure you delete the already created event file in ```logs``` before running the next two cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the model\n",
    "\n",
    "# For Tensorboard\n",
    "logdir = './logs'\n",
    "\n",
    "# To erase any default graphs created before\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholders for the features and labels\n",
    "x_train = tf.placeholder(tf.float32, shape=x_t.shape, name='x_train')\n",
    "y_train = tf.placeholder(tf.float32, shape=(y_t.shape[0], 1), name='y_train')\n",
    "\n",
    "with tf.name_scope('Model_parameters'):\n",
    "    # Weight and bias variables\n",
    "    W = tf.Variable(tf.zeros([NUM_FEATURES, 1]), tf.float32, name='weights')\n",
    "    b = tf.Variable(tf.zeros([1, 1]), tf.float32, name='bias')\n",
    "\n",
    "with tf.name_scope('Forward_propagation'):\n",
    "    # Calculate the predicted value\n",
    "    y_hat = tf.sigmoid(tf.add(tf.matmul(x_train, W), b))\n",
    "\n",
    "with tf.name_scope('Error_calculation'):\n",
    "    # Calculate errors\n",
    "    errors = y_train - y_hat\n",
    "\n",
    "with tf.name_scope('Back_propagation'):\n",
    "    # Calculate the gradients for weights and bias\n",
    "    del_W = tf.matmul(tf.transpose(x_train), errors)\n",
    "    del_b = tf.reduce_sum(errors, 0)\n",
    "\n",
    "    # Update weights\n",
    "    W_ = W + ALPHA*del_W\n",
    "    b_ = b + ALPHA*del_b\n",
    "\n",
    "    # Create an op and assign operations to it\n",
    "    step = tf.group(W.assign(W_), b.assign(b_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #01: train_loss = 0.11978\n",
      "Epoch #02: train_loss = 0.61978\n",
      "Epoch #03: train_loss = -0.38022\n",
      "Epoch #04: train_loss = 0.61978\n",
      "Epoch #05: train_loss = -0.38022\n",
      "Epoch #06: train_loss = 0.61978\n",
      "Epoch #07: train_loss = 0.61978\n",
      "Epoch #08: train_loss = -0.38022\n",
      "Epoch #09: train_loss = 0.61978\n",
      "Epoch #10: train_loss = -0.38022\n"
     ]
    }
   ],
   "source": [
    "## Session\n",
    "\n",
    "# Create a TensorFlow session\n",
    "with tf.Session() as sess:\n",
    "    # Initialize global variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "    \n",
    "    # Train the model\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        print (\"Epoch #{0:02d}\".format(i+1) + \":\", end=' ')\n",
    "        _, outs = sess.run([step, errors], feed_dict={x_train:x_t, y_train:y_t})\n",
    "        outs = [item for sublist in outs for item in sublist]\n",
    "        training_error = np.mean(outs)\n",
    "        print (\"train_loss = {0:0.5f}\".format(training_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
